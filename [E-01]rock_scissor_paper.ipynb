{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e07784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf461ee",
   "metadata": {},
   "source": [
    "# 트레이닝 데이터 불러오기 및 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b94bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2711  images to be resized.\n",
      "2711  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rcp/scissor_tr\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88fe67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708  images to be resized.\n",
      "2708  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rcp/rock_tr\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1561ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2704  images to be resized.\n",
      "2704  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rcp/paper_tr\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610868c",
   "metadata": {},
   "source": [
    "# 데이터 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5959ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 8123 입니다.\n",
      "x_train shape: (8123, 28, 28, 3)\n",
      "y_train shape: (8123,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=8123):  \n",
    "\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor_tr/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock_tr/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper_tr/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rcp\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd02fb",
   "metadata": {},
   "source": [
    "# 데이터 확인 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6cda67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ddc05c",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6217905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 512)       590336    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               6554112   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 7,412,227\n",
      "Trainable params: 7,412,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation = 'relu', input_shape = (28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(512, (3,3), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(keras.layers.Dropout(0.8))\n",
    "model.add(keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(keras.layers.Dropout(0.8))\n",
    "model.add(keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89319130",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b16a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 4s 18ms/step - loss: 5.1335 - accuracy: 0.3629\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.9429 - accuracy: 0.5084\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.7556 - accuracy: 0.6474\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.5839 - accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.4703 - accuracy: 0.8054\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.4111 - accuracy: 0.8289\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.3297 - accuracy: 0.8699\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.2546 - accuracy: 0.9053\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.2318 - accuracy: 0.9159\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.2295 - accuracy: 0.9173\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.2553 - accuracy: 0.9080\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1786 - accuracy: 0.9324\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1974 - accuracy: 0.9296\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1985 - accuracy: 0.9259\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1561 - accuracy: 0.9418\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1381 - accuracy: 0.9479\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1349 - accuracy: 0.9517\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1074 - accuracy: 0.9610\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1120 - accuracy: 0.9606\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0937 - accuracy: 0.9711\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1069 - accuracy: 0.9621\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1101 - accuracy: 0.9629\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1190 - accuracy: 0.9613\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1181 - accuracy: 0.9610\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1312 - accuracy: 0.9580\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0909 - accuracy: 0.9689\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0911 - accuracy: 0.9696\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1200 - accuracy: 0.9620\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1209 - accuracy: 0.9618\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0942 - accuracy: 0.9705\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0838 - accuracy: 0.9743\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0655 - accuracy: 0.9796\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0968 - accuracy: 0.9703\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0767 - accuracy: 0.9761\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.0647 - accuracy: 0.9799\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.0688 - accuracy: 0.9787\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0776 - accuracy: 0.9759\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0720 - accuracy: 0.9794\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0853 - accuracy: 0.9729\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0838 - accuracy: 0.9745\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0709 - accuracy: 0.9771\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0653 - accuracy: 0.9780\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0470 - accuracy: 0.9866\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0537 - accuracy: 0.9825\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0538 - accuracy: 0.9825\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0608 - accuracy: 0.9812\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0736 - accuracy: 0.9765\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0993 - accuracy: 0.9722\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0884 - accuracy: 0.9761\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.1024 - accuracy: 0.9723\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0619 - accuracy: 0.9833\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0409 - accuracy: 0.9883\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0684 - accuracy: 0.9819\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0561 - accuracy: 0.9837\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0628 - accuracy: 0.9840\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0656 - accuracy: 0.9825\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0438 - accuracy: 0.9862\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0915 - accuracy: 0.9764\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0481 - accuracy: 0.9860\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0383 - accuracy: 0.9888\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0528 - accuracy: 0.9855\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0567 - accuracy: 0.9831\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0357 - accuracy: 0.9898\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0336 - accuracy: 0.9909\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0530 - accuracy: 0.9858\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0521 - accuracy: 0.9845\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0476 - accuracy: 0.9871\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0674 - accuracy: 0.9820\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0345 - accuracy: 0.9898\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0399 - accuracy: 0.9873\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0468 - accuracy: 0.9894\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0326 - accuracy: 0.9899\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0426 - accuracy: 0.9871\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0479 - accuracy: 0.9887\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0401 - accuracy: 0.9894\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0588 - accuracy: 0.9826\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0467 - accuracy: 0.9879\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0527 - accuracy: 0.9870\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0650 - accuracy: 0.9826\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0531 - accuracy: 0.9887\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0447 - accuracy: 0.9892\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0400 - accuracy: 0.9906\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0359 - accuracy: 0.9899\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0533 - accuracy: 0.9852\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0331 - accuracy: 0.9893\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0371 - accuracy: 0.9897\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0387 - accuracy: 0.9897\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0686 - accuracy: 0.9845\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0792 - accuracy: 0.9793\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0717 - accuracy: 0.9835\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0568 - accuracy: 0.9852\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0704 - accuracy: 0.9826\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0549 - accuracy: 0.9866\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0374 - accuracy: 0.9903\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0429 - accuracy: 0.9888\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0251 - accuracy: 0.9930\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0398 - accuracy: 0.9906\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0406 - accuracy: 0.9900\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0641 - accuracy: 0.9847\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.0523 - accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7660ce8340>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeefbe6",
   "metadata": {},
   "source": [
    "# 테스트 데이터셋 불러오기 및 가공,라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce522f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800  images to be resized.\n",
      "800  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "800  images to be resized.\n",
      "800  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "800  images to be resized.\n",
      "800  images resized.\n",
      "보 이미지 resize 완료!\n",
      "학습데이터(x_test)의 이미지 개수는 2400 입니다.\n",
      "x_test shape: (2400, 28, 28, 3)\n",
      "y_test shape: (2400,)\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rcp/test2/scissor_t\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rcp/test2/rock_t\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rcp/test2/paper_t\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "def load_data(img_path, number_of_data=2400):\n",
    "    img_size=28\n",
    "    color=3\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor_t/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=0   \n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock_t/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=1   \n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper_t/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2   \n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rcp/test2\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   \n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc5df1",
   "metadata": {},
   "source": [
    "# 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2f75d28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 - 0s - loss: 3.7765 - accuracy: 0.7242\n",
      "test_loss:3.7764627933502197\n",
      "test_accuracy : 0.7241666913032532\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose = 2)\n",
    "print('test_loss:{}'.format(test_loss))\n",
    "print('test_accuracy : {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718262a4",
   "metadata": {},
   "source": [
    "# 프로젝트 회고\n",
    "\n",
    "이것저것 에러가 뜨는 걸 잡고 처음 돌렸을 때 35%의 정확도를 보였다.\n",
    "모델을 깊게 만들고 드롭아웃과 배치사이즈 에포크 등을 고치면 60%는 금방 넘을 줄 알았다.\n",
    "하지만 코드를 고치기만 해서는 52%까지 밖에 올릴 수 없었다.\n",
    "결국 데이터셋을 열심히 모았고, 300개였던 트레이닝셋을 8123개까지 모았다.\n",
    "트레이닝셋을 모으고 기대를 하며 모델의 정확도를 봤는데 accuracy: 0.3333을 보고는 어떻게 정확도가 더 내려갈 수 있는건지 의아했다.\n",
    "다시 모델을 고치고 레이어를 추가해보고 실행하고를 반복해서 92%의 정확도를 보고는 뿌듯했었다.\n",
    "하지만 그 때 모델의 테스트셋은 내가 찍은 사진들로만 구성되어 있었고,\n",
    "다른 사람의 테스트 셋을 가지고 테스트 해보니까 코드를 실행시킬때 마다 33~86까지 고점은 높지만 너무나 불안정한 모델이었다.\n",
    "왜 그럴까 고민을 하다가 테스트 셋이 한 사람만의 사진이기 때문인 것은 아닐까하고 여러 사람들의 테스트 셋을 섞어서 2400개의 테스트 셋을 만들었다.\n",
    "여러 사람의 테스트 셋을 사용하니 33~40정도로 안정적(?)이지만 고점이 없다시피한 테스트 결과가 나왔다.\n",
    "또다시 Dense층을 여러층 쌓아보기도 하고 드롭아웃 수를 조절하고 옵티마이저를 adam에서 Nadam을 사용해보기도 하고\n",
    "배치사이즈를 조정하기도 하며 여러 테스트를 하다가\n",
    "지금의 모델이 여러번 새로 돌려도 62~78까지의 안정적이면서 고점도 어느정도 괜찮은 모델이라고 판단했다.\n",
    "\n",
    "이전까지는 공부를 하던 프로젝트를 해보던 남들이 만들어놓은 모델을 보거나 사용해서 프로젝트를 했었다.\n",
    "에러는 검색을 해가면서 잡아나갔지만 사실 이 코드가 왜 이렇게 만들어진건지, 왜 이런방식을 썼는지도 이해를 못했었다.\n",
    "남이 사용하던 모델을 사용할 때 가장 힘들었던 것이 내가 코드를 사용하는데 익숙하지 않다보니 정확도를 위해서 건드려보고 싶어도\n",
    "에러가 날까봐 코드를 건드릴 수 없었다는 것이었다.\n",
    "하지만 이번 프로젝트는 코드를 한줄한줄 다 이해한 것은 아니었지만\n",
    "적어도 코드가 어떤식으로 흘러가는지 어떤 부분을 건드렸을 때 어떤 에러가 나는지 어떻게 에러를 잡을 수 있는지 알 수 있었고,\n",
    "모델을 내가 직접 만들어보고 이것저것 추가도해보고 사이즈 조절도 해가면서 코드를 가지고 놀아보니까\n",
    "정말 재미있었고 정확도가 잘나오면 은근 뿌듯했다.\n",
    "\n",
    "아직은 첫번째 프로젝트라서 모든 코드를 직접 작성할 수는 없었지만\n",
    "나의 목표는 이런 딥러닝 모델 코드를 혼자서 작성하는 것이기 때문에 \n",
    "재밌다에서 그치지 않고 더 열심히 공부해서 아이펠이 끝날때 쯤에는\n",
    "혼자서 이런 프로젝트를 할 수 있었게 할 것이다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
